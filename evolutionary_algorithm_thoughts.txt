# Just writing out my thoughts here for before actually starting the implementation
# engine.py already handles the initialization of the board and the game logic
# it also already defines the solution representation (a 2D list of integers) and the goal state

# for the evolutionary algorithm, we need to define the evolutionary operators (selection, crossover, mutation)

# the selection will be done based on the fitness function/heuristic that Eddie has defiened (number of placed numbers)
# because we are trying to find the optimal soulution, we will only select parents that have a higher fitness than the current best solution

# How do we get new individuals?
# Crossover doesn't make much sense because there is not really a benefit in combining two solutions to get a better one
# Also, crossover could change the fixed numbers in the board, which is not allowed
# Instead, we will only use mutation to get new individuals
# Mutation should be done by randomly changing a 0 in the board to a number between 1 and 9
# Changing existing numbers will never lead to a better solution, so we will not do that

# How many individuals do we want to keep in the population?
# Does it make sense to keep all the individuals that have a higher fitness than the current best solution?
# That would lead to exponential growth of the population size in the beginning and large time and space complexity (and would just behave like a breadth-first search)
# Instead, we should only keep a fixed number of individuals in the population
# For lack of information right now, we will just keep the best 100 individuals in the population

# What would be parameter tuning in this context?
# We could tune the mutation rate (how many mutations per individual per generation)
# We could also tune the population size (how many individuals to keep in the population)

------------

Problem with the selection:
- if we only select the best parents, we might run into local maxima where all of the boards lead to no solution

How do we keep mutating?
- if we only mutate every parent excatly once we will get a decrease in population as some mutations will place invalid numbers
- so we also have to distinguish between invalid numbers and the fitness funtion staying the same
- is it allowed to only mutate to a valid number?
- we could choose random boards to mutate, BUT that could lead to the initial board being discarded and creating offspring of only
    unsolvable boards
        - how do we guarentee that at least one board in the population is solvable? Increase the population?
- I think we need to change the fitness function
- only caring about unqiue numbers placed completely disregards if the path we are on leads to the goal or not
- or also need to consider how many possible number placements we have left and heavily punish paths leading to a dead end
        - maybe something like unique numbers placed + possible unique numbers to place
- that should help keep the solution in at every point
- What about the selection? We shouldn't exclusively select the best individuals of a generation right? (at least in the beginning)
- Use some form of simulated annealing where instead of choosing the next number it helps us decide what boards to take with us 
    into the next generation (but how to guarentee best solution is there by chance?) Only using the best individuals?

-------------

Meeting:
- initialize the solution randomly (randomly completely filled out boards)
- heuristic to tell how good a board is
- somehow need to tell which numbers are at the right spot (isValid by Hoaran)
--> either crossover tiles randomly (not checking valid numbers), or only taking correct numbers BUT then watch the computational time. Needs to be fast
(Try both but start with random crossover)
- select 90% best and 10% random
- keep the valid numbers of both parents and randomly mutate all of the "wrong" numbers
- crossover parents randomly

Run the algorithm several times to see if it is actually good (at least 25x)
DFS as baseline for now to compare (should not work on hard examples anymore or be much worse)



TODO:
- todo: not using such a big population size
- use bigger matrixes for baseline
- compare our different algorithms with each other

--------------------------

Structure Presentation:
- Topic (Ben): Sudoku Puzzle
    Solving 9x9 boards in 3 difficulties and (originally planned), also solve 16x16 and 25x25 boards
    2 implementations of GA. One simple random, other with improvments/extra logic
    DFS as baseline to compare performance

- Code
    - Board (Eddie) are randomly generated by .py (DFS to generate filled boards, take away number and see if solvable, repeat until difficulty level is met)
    - simple GA (Moritz):
        - take board of medium, initialization, crossover and mutation random. Selection top 20% create 80% offspring, rest is randomly selected
        - it is too random, if it ever finds solution it takes a loooong time
    - fitness (Eddie):
        - sum up number of unique numbers in row, coloum and 3x3, update function to cash results so mutation we don't have to calc all again
    - improved GA (Haoran):
        - initialization rows "correctly". only focus on coloum and 3x3.
        - crossover: best parents (either row of parent1 or partent2 for all rows)
        - selection: tournament function (2 random individuals, better one gets selected)
        (- 10 elites will also be taken over without change)
        - mutation: only in row
        (- fitness: only calculate violations, so 0 means solution found, no need to calculate row)
        - extra: if generations stuck (500 without improvement), generate some completely new boards and combine with worst of stuck generation
        - mutation rate is also increased if stuck
    - Bayesian Optimazaion (Moritz):
        - find best hyperparameter with Bayesian Optimazaion (population and mutation rate)
    - DFS (Eddie):
        - rule based search with backtracking

- Results (if needed)
- Paper (Ben)